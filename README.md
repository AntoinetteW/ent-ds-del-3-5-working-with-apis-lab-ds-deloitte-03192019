
# Working with APIs - Lab


## Introduction
We are almost done! Now it's time to practice the hardest part of working with API's - exploring them to find interesting information and insights!

## Objectives
You will be able to:
* Query information from the NY Times API, retrieve the results and transform a subset of the data into DataFrames

## What do You Want to Find Out?!

Go back to the [developer home page](https://developer.nytimes.com) at the New York Times. In the time remaining in class today:
* Pick at least one new API
* Create a new "app" with access to that API
* Read the documentation for the API
* Write a script to retrieve information from the API
* Deserialize the resulting response using the appropriate Python library
* Write some exploratory code to look at the data returned
* Load an interesting subset of the data into a DataFrame

For bonus points:
* Change the data type of any numerical information into the appropriate type to get the mean of the values
* Look at filtering based on any categorical variables to only save a subset of the data to your DataFrame

**Really take the time to play and explore.**

***A few final hints, before you go off on your own to explore:***
* Don't be worried when you find bugs in your code. Bugs happen. The only difference is that over time, you get quicker at fixing them. The reason you get quicker at fixing them is because you get more practice. So more bugs == quicker improvement as a developer!
* Take very small steps. Usually it's when you take bigger steps that you fall over you own feet
* Feel free to look at previous labs for sample code. But if possible, instead of cutting and pasting, type it back in. It isn't much slower and it'll start to make you more comfortable with the code.
* And finally, remember, there is an instructor in the room for a reason. If you're getting stuck, ask them for help!

Good luck with your explorations!


## Summary

Now we have come a really long way since starting this course. You're writing scripts to access APIs, deserialize the data, transform interesting subsets of the data into DataFrames, and then clean up the data. Take a moment to reflect on just how much you've learned!

Next up, we'll be looking at how you can use web scraping to access information that might not be available via an API.

